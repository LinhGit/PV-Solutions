{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38713b2a",
   "metadata": {},
   "source": [
    "# Convert OpenSfM reconstruction to format used by our tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457726cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import g2o\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import tqdm\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from extractor.mapping.geotransforms import enu2geodetic, geodetic2enu\n",
    "from extractor.mapping.geometry import from_twist\n",
    "from extractor.common import get_immediate_subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e651842",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/storage-2/pvextractor-georeferencing/20210510_Schmalenbach/workdir/02_north\"\n",
    "mapping_root = os.path.join(work_dir, \"mapping\")\n",
    "\n",
    "# find all clusters\n",
    "reconstruction_files = []\n",
    "tracks_file = os.path.join(work_dir, \"tracking\", \"tracks.csv\")\n",
    "patches_meta_file = os.path.join(work_dir, \"patches\", \"meta.pkl\")\n",
    "\n",
    "for cluster_dir in sorted(get_immediate_subdirectories(mapping_root)):\n",
    "    reconstruction_file = os.path.join(mapping_root, cluster_dir, \"reconstruction.json\")\n",
    "    \n",
    "    if os.path.isfile(reconstruction_file):\n",
    "        reconstruction_files.append(reconstruction_file)\n",
    "        \n",
    "assert len(reconstruction_files) > 0, \"No reconstructions found. Run OpenSfM first.\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "2eacd4f1-3c08-4bb3-9eb9-6eb23f5ec968",
   "metadata": {},
   "source": [
    "# overvwrite reconstruction files\n",
    "reconstruction_files = [\n",
    "    #\"reconstruction.json\",\n",
    "    \"reconstruction_twoparts_part1_old.json\",\n",
    "    \"reconstruction_twoparts_part2_old.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722710d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reconstructions: 3\n"
     ]
    }
   ],
   "source": [
    "reconstructions = []\n",
    "for file in reconstruction_files:\n",
    "    reconstructions.extend(json.load(open(file, \"r\")))\n",
    "\n",
    "print(\"Number of reconstructions: {}\".format(len(reconstructions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a5af8",
   "metadata": {},
   "source": [
    "### Equalize reference points of reconstructions\n",
    "\n",
    "When combining multiple reconstructions each one uses its own ECEF origin. To equalize them, we select the origin of the first reconstruction and convert all other reconstructions to this origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e48c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_origin = tuple(reconstructions[0][\"reference_lla\"].values())\n",
    "pickle.dump(overall_origin, open(os.path.join(mapping_root, \"reference_lla.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452d3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert reconstruction from ECEF to WGS-84 using its own origin\n",
    "# pick one of the origins as overall origin, e.g. pick the one of the first reconstruction\n",
    "# convert reconstruction back to ECEF using the overall origin\n",
    "# Note: This may take a while.\n",
    "for reconstruction in reconstructions:\n",
    "    origin = tuple(reconstruction[\"reference_lla\"].values())\n",
    "    if origin == overall_origin:\n",
    "        continue\n",
    "    \n",
    "    # transform map points\n",
    "    for i, point_id in enumerate(reconstruction[\"points\"].keys()):\n",
    "        geo = enu2geodetic(*reconstruction[\"points\"][point_id][\"coordinates\"], *origin)\n",
    "        transformed_ecef = geodetic2enu(*geo, *overall_origin)\n",
    "        reconstruction[\"points\"][point_id][\"coordinates\"] = transformed_ecef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad46be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reconstruction in reconstructions:\n",
    "    origin = tuple(reconstruction[\"reference_lla\"].values())\n",
    "    if origin == overall_origin:\n",
    "        continue\n",
    "    \n",
    "    # transform camera poses\n",
    "    for i, shot_id in enumerate(reconstruction[\"shots\"].keys()):\n",
    "        shot = reconstruction[\"shots\"][shot_id]\n",
    "        R, _ = cv2.Rodrigues(np.array(shot[\"rotation\"]))\n",
    "        t = np.array(shot[\"translation\"])\n",
    "        t = -R.T.dot(t)        \n",
    "        geo = enu2geodetic(*t, *origin)\n",
    "        transformed_ecef = geodetic2enu(*geo, *overall_origin)        \n",
    "        transformed_ecef = -1.0 * (R @ np.array(transformed_ecef).reshape(3, 1)).reshape(3,)\n",
    "        reconstruction[\"shots\"][shot_id][\"translation\"] = transformed_ecef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb1c1a",
   "metadata": {},
   "source": [
    "### Convert map points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "104ae403",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_points = []\n",
    "for reconstruction in reconstructions:\n",
    "    for i, point in enumerate(reconstruction['points'].values()):\n",
    "        map_points.append(point['coordinates'])\n",
    "map_points = np.vstack(map_points)\n",
    "pickle.dump(map_points, open(os.path.join(mapping_root, \"map_points.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d380654",
   "metadata": {},
   "source": [
    "### Convert camera poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55cd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_graphs = []\n",
    "i = 0\n",
    "for reconstruction in reconstructions:\n",
    "    pose_graph = nx.Graph()\n",
    "    for frame_name in sorted(reconstruction['shots']):\n",
    "        shot = reconstruction['shots'][frame_name]\n",
    "        R, _ = cv2.Rodrigues(np.array(shot[\"rotation\"]))\n",
    "        t = np.array(shot[\"translation\"])\n",
    "        t = -R.T.dot(t)\n",
    "        R, _ = cv2.Rodrigues(R.T)\n",
    "        pose = np.hstack((R.reshape(3,), t))\n",
    "        frame_name = str.split(frame_name, \".\")[0]\n",
    "        pose_graph.add_node(frame_name, pose=pose)\n",
    "        i += 1\n",
    "    pose_graphs.append(pose_graph)\n",
    "    \n",
    "pose_graph = nx.compose_all(pose_graphs)\n",
    "pickle.dump(pose_graph, open(os.path.join(mapping_root, \"pose_graph.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a0833",
   "metadata": {},
   "source": [
    "### Convert camera matrix and distortion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ae7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_camera_matrix(reconstruction, camera_model=\"brown\"):\n",
    "    \"\"\"Convert camera matrix from OpenSfM format to OpenCV format \n",
    "    (pixel units). Needed because OpenSfM modifies camera parameters \n",
    "    during the reconstruction.\"\"\"\n",
    "    \n",
    "    if camera_model == \"brown\":\n",
    "        camera = list(reconstruction['cameras'].keys())[0]\n",
    "        image_width = reconstruction['cameras'][camera]['width']\n",
    "        image_height = reconstruction['cameras'][camera]['height']\n",
    "        scale = np.maximum(image_width, image_height)\n",
    "        fx = reconstruction['cameras'][camera]['focal_x'] * scale\n",
    "        fy = reconstruction['cameras'][camera]['focal_y'] * scale\n",
    "        cx = reconstruction['cameras'][camera]['c_x'] * scale + 0.5*image_width\n",
    "        cy = reconstruction['cameras'][camera]['c_y'] * scale + 0.5*image_height\n",
    "\n",
    "        camera_matrix = np.array([[fx, 0.0, cx],\n",
    "                                  [0.0, fy, cy],\n",
    "                                  [0.0, 0.0, 1.0]])\n",
    "\n",
    "        k1 = reconstruction['cameras'][camera]['k1']\n",
    "        k2 = reconstruction['cameras'][camera]['k2']\n",
    "        p1 = reconstruction['cameras'][camera]['p1']\n",
    "        p2 = reconstruction['cameras'][camera]['p2']\n",
    "        k3 = reconstruction['cameras'][camera]['k3']\n",
    "        dist_coeffs = np.array([[k1, k2, p1, p2, k3]])\n",
    "        \n",
    "    elif camera_model == \"perspective\":\n",
    "        dist_coeffs = None\n",
    "        camera = list(reconstruction['cameras'].keys())[0]\n",
    "        image_width = reconstruction['cameras'][camera]['width']\n",
    "        image_height = reconstruction['cameras'][camera]['height']\n",
    "        scale = np.maximum(image_width, image_height)\n",
    "        focal = reconstruction['cameras'][camera]['focal'] * scale\n",
    "        cx = image_width / 2\n",
    "        cy = image_height / 2\n",
    "        camera_matrix = np.array([[focal, 0.0, cx],\n",
    "                                  [0.0, focal, cy],\n",
    "                                  [0.0, 0.0, 1.0]])\n",
    "    \n",
    "    return camera_matrix, dist_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4096647b-f537-4257-93c8-5c24f2b16ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert camera matrix and distortion coefficients into pose graph\n",
    "for reconstruction in reconstructions:\n",
    "    camera_matrix, dist_coeffs = convert_camera_matrix(reconstruction)\n",
    "    for frame_name in sorted(reconstruction['shots']):\n",
    "        frame_name = str.split(frame_name, \".\")[0]\n",
    "        pose_graph.nodes[frame_name][\"camera_matrix\"] = camera_matrix\n",
    "        pose_graph.nodes[frame_name][\"dist_coeffs\"] = dist_coeffs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6ceed30-5b78-4a23-89d1-1509e1a54f79",
   "metadata": {},
   "source": [
    "for reconstruction in reconstructions:\n",
    "    print(reconstruction[\"cameras\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3b5c8-a3a6-4f77-9563-669fff2b747a",
   "metadata": {},
   "source": [
    "### Reduce size of reconstruction for faster development"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b7e2fdf-4d61-4355-b021-293c894fd14e",
   "metadata": {},
   "source": [
    "limit = 200\n",
    "for i, frame_name in enumerate(pose_graph.copy()):\n",
    "    if i >= limit:\n",
    "        pose_graph.remove_node(frame_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ab4f1",
   "metadata": {},
   "source": [
    "### Triangulate PV module corners and centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82dbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_modules(module_corners):\n",
    "    module_centers_ = {track_id: pts_3d[0, :].reshape(1, 3) for track_id, pts_3d in module_corners.items()}\n",
    "    module_corners_ = {track_id: pts_3d[1:, :].reshape(-1, 3) for track_id, pts_3d in module_corners.items()}\n",
    "\n",
    "    modules = {\n",
    "        \"corners\": module_corners_,\n",
    "        \"centers\": module_centers_\n",
    "    }\n",
    "    pickle.dump(modules, open(os.path.join(mapping_root, \"modules.pkl\"), \"wb\"))\n",
    "    \n",
    "\n",
    "def save_modules_geocoords(module_corners, gps_origin):\n",
    "    \"\"\"Save WGS-84 coordinates of PV modules in GeoJSON file.\"\"\"\n",
    "    module_centers_ = {track_id: pts_3d[0, :].reshape(1, 3) for track_id, pts_3d in module_corners.items()}\n",
    "    module_corners_ = {track_id: pts_3d[1:, :].reshape(-1, 3) for track_id, pts_3d in module_corners.items()}    \n",
    "    \n",
    "    module_geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    for track_id in module_corners.keys():\n",
    "        \n",
    "        # module outlines as polygons\n",
    "        polygons = []\n",
    "        for corner in module_corners_[track_id][::-1]:  # polygon must be right-handed\n",
    "            lat, lon, alt = enu2geodetic(*corner, *gps_origin)\n",
    "            polygons.append([lon, lat, alt])\n",
    "        # repeat first corner to form a closed polygon\n",
    "        corner = module_corners_[track_id][-1]\n",
    "        lat, lon, alt = enu2geodetic(*corner, *gps_origin)\n",
    "        polygons.append([lon, lat, alt])\n",
    "        \n",
    "        module_geojson[\"features\"].append(\n",
    "        {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Polygon\",\n",
    "                \"coordinates\": [\n",
    "                    polygons\n",
    "                ]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"track_id\": track_id\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # module centers as points\n",
    "        lat, lon, alt = enu2geodetic(*module_centers_[track_id].reshape(3,), *gps_origin)\n",
    "        point = [lon, lat, alt]\n",
    "        \n",
    "        module_geojson[\"features\"].append(\n",
    "        {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": point\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"track_id\": track_id\n",
    "            }\n",
    "        })\n",
    "    json.dump(module_geojson, open(os.path.join(mapping_root, \"module_geolocations.geojson\"), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2dd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_bearings(pts, camera_rotation, camera_matrix):\n",
    "    \"\"\"Returns the bearing vectors for given image points.\n",
    "    \n",
    "    Args:\n",
    "        pts (`numpy.ndarray`): Image points (u, v) in pixel coordinates. \n",
    "            Shape should be either (-1, 2) or (-1, 1, 2).\n",
    "        \n",
    "        rvec (`numpy.ndarray`): Camera rotations matrix (see cv2.Rodrigues).\n",
    "            It is the rotation which transforms points from image coordinates\n",
    "            into world coordinates. Note: This is inverse of the OpenCV\n",
    "            convention in which the transformation maps points from world\n",
    "            to camera coordinates.\n",
    "        \n",
    "        camera_matrix (`numpy.ndarray`): OpenCv camera matrix in pixel units.\n",
    "        \n",
    "    Returns:\n",
    "        bearings (`numpy.ndarray`): Bearing vector for each point. Array of \n",
    "            shape (-1, 3).\n",
    "    \"\"\"\n",
    "    # compute bearing vectors    \n",
    "    c = np.array([camera_matrix[0, 2], camera_matrix[1, 2]])\n",
    "    f = np.array([camera_matrix[0, 0], camera_matrix[1, 1]])\n",
    "    \n",
    "    # compute bearing for each point\n",
    "    pts = pts.reshape(-1, 2)\n",
    "    b = np.ones((pts.shape[0], 3))\n",
    "    b[:, :2] = (pts - c) / f\n",
    "    b /= np.linalg.norm(b, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # rotate bearings by camera rotation\n",
    "    b = np.matmul(camera_rotation, b.T).T\n",
    "    return b\n",
    "\n",
    "\n",
    "def angle_between_vectors(u, v):\n",
    "    \"\"\"Returns the angle between two vectors of vectors in radians.\n",
    "    \n",
    "    Args:\n",
    "        u (`numpy.ndarray`): Shape (-1, 3). Each row is a separate\n",
    "            3D-vector.\n",
    "            \n",
    "        v (`numpy.ndarray`): Shape (-1, 3). Each row is a separate\n",
    "            3D-vector.\n",
    "            \n",
    "    Returns:\n",
    "        angles (`numpy.ndarray`): Shape (-1,). The ith entry corresponds\n",
    "            to the angle (in radians) between the ith row in u and v.\n",
    "    \"\"\"\n",
    "    u = u.reshape(-1, 3)\n",
    "    v = v.reshape(-1, 3)\n",
    "    s1 = np.diagonal(np.matmul(u, u.T))\n",
    "    s2 = np.diagonal(np.matmul(v, v.T))\n",
    "    c = np.diagonal(np.matmul(u, v.T)) / np.sqrt(s1 * s2)    \n",
    "    c[np.abs(c) >= 1.0] = 0.0\n",
    "    c[np.abs(c) < 1.0] = np.arccos(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "def triangulate_points(pts1, pts2, R1, t1, R2, t2, camera_matrix1, camera_matrix2,\n",
    "        reproj_thres=5.0, min_ray_angle_degrees=1.0):\n",
    "    \"\"\"Triangulate 3D map points from corresponding points in two\n",
    "    keyframes. R1, t1, R2, t2 are the rotation and translation of\n",
    "    the two key frames w.r.t. to the map origin. Also check for\n",
    "    the reprojection error in both frames.\n",
    "    \"\"\"\n",
    "    # if any ray angle is smaller than threshold, mark triangulation as failed\n",
    "    if min_ray_angle_degrees is not None:\n",
    "        b1 = pixel_bearings(pts1, R1, camera_matrix1)\n",
    "        b2 = pixel_bearings(pts2, R2, camera_matrix2)\n",
    "        angles = angle_between_vectors(b1, b2) * 180.0/math.pi\n",
    "        if np.sum(angles < min_ray_angle_degrees):\n",
    "            #print(\"Ray angle below threshold\")\n",
    "            return False, np.empty(shape=(0, 3), dtype=np.float64)\n",
    "    \n",
    "    # create projection matrices needed for triangulation of 3D points\n",
    "    proj_matrix1 = np.hstack([R1.T, -R1.T.dot(t1)])\n",
    "    proj_matrix2 = np.hstack([R2.T, -R2.T.dot(t2)])\n",
    "    proj_matrix1 = camera_matrix1.dot(proj_matrix1)\n",
    "    proj_matrix2 = camera_matrix2.dot(proj_matrix2)\n",
    "\n",
    "    # triangulate new map points based on matches with previous key frame\n",
    "    pts_3d = cv2.triangulatePoints(proj_matrix1, proj_matrix2, pts1.reshape(-1, 2).T, pts2.reshape(-1, 2).T).T\n",
    "    pts_3d = cv2.convertPointsFromHomogeneous(pts_3d).reshape(-1, 3)\n",
    "    \n",
    "    # if any reprojection error exceeds threshold, mark triangulation as failed\n",
    "    if reproj_thres is not None:\n",
    "        for R, t, pts, camera_matrix in [(R1, t1, pts1, camera_matrix1), \n",
    "                                         (R2, t2, pts2, camera_matrix2)]:     \n",
    "            rvec, _ = cv2.Rodrigues(R.T)\n",
    "            tvec = -R.T.dot(t)\n",
    "            reproj_pts, _ = cv2.projectPoints(pts_3d, rvec, tvec, camera_matrix, None)\n",
    "            reproj_err = np.linalg.norm(reproj_pts - pts, axis=2)\n",
    "\n",
    "            if np.sum(reproj_err > reproj_thres):\n",
    "                #print(\"Reprojection error exceeds threshold\")\n",
    "                return False, np.empty(shape=(0, 3), dtype=np.float64)\n",
    "    \n",
    "    return True, pts_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742aeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tracks(tracks_file):\n",
    "    \"\"\"Load Tracks CSV file.\"\"\"\n",
    "    tracks_per_frame = defaultdict(list)\n",
    "    tracks_per_id = defaultdict(list)\n",
    "    with open(tracks_file, newline='', encoding=\"utf-8-sig\") as csvfile:  # specifying the encoding skips optional BOM\n",
    "        # automatically infer CSV file format\n",
    "        dialect = csv.Sniffer().sniff(csvfile.readline(), delimiters=\",;\")\n",
    "        csvfile.seek(0)\n",
    "        csvreader = csv.reader(csvfile, dialect)\n",
    "        for row in csvreader:\n",
    "            frame_name = row[0]\n",
    "            mask_name = row[1]\n",
    "            track_id = row[2]\n",
    "            tracks_per_frame[frame_name].append((mask_name, track_id))\n",
    "            tracks_per_id[track_id].append((frame_name, mask_name))\n",
    "    return tracks_per_frame, tracks_per_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f14ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_points(metas, track_id, frame_name, mask_name, camera_matrix=None, dist_coeffs=None):\n",
    "    \"\"\"Loads module corners and center points. Undistorts points if dist_coeffs and camera_matrix are not None.\"\"\"\n",
    "    try:\n",
    "        meta = metas[(track_id, frame_name, mask_name)]\n",
    "    except KeyError:\n",
    "        points = None\n",
    "        print(\"Meta data for module {} not found\".format(track_id))\n",
    "    else:\n",
    "        center = np.array(meta[\"center\"]).reshape(1, 2).astype(np.float64)\n",
    "        quadrilateral = np.array(meta[\"quadrilateral\"]).reshape(-1, 2).astype(np.float64)\n",
    "        points = np.vstack((center, quadrilateral))\n",
    "        \n",
    "        if dist_coeffs is not None:\n",
    "            points = cv2.undistortPoints(points, camera_matrix, dist_coeffs, None, camera_matrix)\n",
    "            \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db5520a-42c9-4597-9e5a-971527edeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate_observations(pose_graph, observations, max_combinations=None):\n",
    "    \"\"\"Triangulates PV module corners (and centers) by triangulating\n",
    "    observations from all possible 2-pairs of frames and computing the\n",
    "    median points in 3D space.\n",
    "    \n",
    "    Args:\n",
    "        pose_graph (`networkx.Graph`): Pose graph containing camera poses\n",
    "            in the world frame.\n",
    "        \n",
    "        observations (`dict` of `dict`): The outer dictionary is indexed by\n",
    "            the track_id of the module. The inner dictionary is indexed\n",
    "            by the frame_name (`str`) and contains a `numpy.ndarray` of\n",
    "            shape (5, 1, 2) of undistorted pixel coordinates of the PV module \n",
    "            corners in the respective frame. The first row is the center point, \n",
    "            the other rows correspond to the top-left (tl), tr, br and bl points.\n",
    "    \n",
    "        max_combinations (`int` or `None`): If None triangulate points from all\n",
    "            possible 2-pairs of frames. To limit this number specify the maximum\n",
    "            number of combinations to try here.\n",
    "    \n",
    "    Returns:\n",
    "        module_corners (`dict`): Triangulated 3D points of each module. Index is \n",
    "            the module track_id and value is a `numpy.ndarray` of shape (5, 3).\n",
    "            The meaning of rows in this array corresponds to the meaning of\n",
    "            rows in the observations.\n",
    "    \"\"\"\n",
    "    module_corners = {}\n",
    "\n",
    "    for track_id in tqdm.tqdm_notebook(observations.keys()):\n",
    "        num_observations = len(observations[track_id])\n",
    "        frame_names = list(observations[track_id].keys())\n",
    "\n",
    "        all_combinations = list(combinations(range(num_observations), 2))\n",
    "\n",
    "        # limit number of combinations to try\n",
    "        random.shuffle(all_combinations)\n",
    "        all_combinations = all_combinations[:max_combinations]\n",
    "\n",
    "        pts_3d = []\n",
    "        for i, j in all_combinations:\n",
    "\n",
    "            R1, t1 = from_twist(pose_graph.nodes[frame_names[i]][\"pose\"])\n",
    "            R2, t2 = from_twist(pose_graph.nodes[frame_names[j]][\"pose\"])\n",
    "\n",
    "            pts1 = observations[track_id][frame_names[i]]\n",
    "            pts2 = observations[track_id][frame_names[j]]\n",
    "            \n",
    "            camera_matrix1 = pose_graph.nodes[frame_names[i]][\"camera_matrix\"]\n",
    "            camera_matrix2 = pose_graph.nodes[frame_names[j]][\"camera_matrix\"]\n",
    "\n",
    "            valid, pts = triangulate_points(pts1, pts2, R1, t1, R2, t2, camera_matrix1, camera_matrix2)\n",
    "            if valid:\n",
    "                pts_3d.append(pts)\n",
    "            #else:\n",
    "            #    print(\"Invalid triangulation for track id {} and combination {} {}\".format(track_id, i, j))\n",
    "\n",
    "        if len(pts_3d) > 0:\n",
    "            pts_3d = np.median(pts_3d, axis=0)\n",
    "            module_corners[track_id] = pts_3d\n",
    "    return module_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73aed7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc2ec96f35d400493032bb8d5d3c693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7130.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bbd6674552458c8b5f8c21853c631c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe8c277709443258cecd0070a3fca4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_per_frame, tracks_per_id = load_tracks(tracks_file)\n",
    "metas = pickle.load(open(patches_meta_file, \"rb\"))\n",
    "\n",
    "# keep only tracks of key frames\n",
    "tracks_per_id_filtered = defaultdict(list)\n",
    "for track_id, frame_mask_names in tqdm.tqdm_notebook(tracks_per_id.items()):\n",
    "    for frame_mask_name in frame_mask_names:\n",
    "        frame_name, mask_name = frame_mask_name\n",
    "        if frame_name in pose_graph.nodes:\n",
    "            tracks_per_id_filtered[track_id].append((frame_name, mask_name))\n",
    "            \n",
    "# filter out short tracks\n",
    "min_track_len = 3\n",
    "assert min_track_len >= 2, \"min_track_len must be >= 2\"\n",
    "tracks_per_id_filtered = {k: v for k, v in tracks_per_id_filtered.items() if len(v) >= min_track_len}\n",
    "\n",
    "# get module observations\n",
    "observations = {}\n",
    "for track_id, frame_mask_names in tqdm.tqdm_notebook(tracks_per_id_filtered.items()):\n",
    "    observations[track_id] = {}\n",
    "    for frame_name, mask_name in frame_mask_names:\n",
    "        camera_matrix = pose_graph.nodes[frame_name][\"camera_matrix\"]\n",
    "        dist_coeffs = pose_graph.nodes[frame_name][\"dist_coeffs\"]\n",
    "        points = get_module_points(metas, track_id, \n",
    "            frame_name, mask_name, camera_matrix, dist_coeffs)\n",
    "        if points is not None:\n",
    "            observations[track_id][frame_name] = points\n",
    "\n",
    "# triangulate \n",
    "module_corners = triangulate_observations(pose_graph, observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c403295",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modules(module_corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba448e6a",
   "metadata": {},
   "source": [
    "### Merge Duplicate PV Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8d190",
   "metadata": {},
   "source": [
    "Principle\n",
    "  - for each keyframe\n",
    "  - project 3D points of all modules into the key frames\n",
    "  - determine which modules are fully visible (i.e. all 5 points are visible)\n",
    "  - find modules for which the projected points lie very close to another in image space and select those as merging candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed682c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visible_modules(pose_graph, frame_name, module_corners, image_width, image_height):\n",
    "    \"\"\"Obtain track IDs and reprojected 2D points of all modules visible in the specified key frame.\"\"\"\n",
    "    visible_modules = []\n",
    "    \n",
    "    # project all modules into key frame\n",
    "    R, t = from_twist(pose_graph.nodes[frame_name][\"pose\"])\n",
    "    camera_matrix = pose_graph.nodes[frame_name][\"camera_matrix\"]\n",
    "    for track_id, pts_3d in module_corners.items():\n",
    "        rvec, _ = cv2.Rodrigues(R.T)\n",
    "        tvec = -R.T.dot(t)\n",
    "        reproj_pts, _ = cv2.projectPoints(pts_3d, rvec, tvec, camera_matrix, None)\n",
    "        reproj_pts = reproj_pts.reshape(-1, 2)\n",
    "        \n",
    "        # determine if module is fully visible\n",
    "        if (all(reproj_pts[:, 0] >= 0.0) \n",
    "            and all(reproj_pts[:, 0] < image_width) \n",
    "            and all(reproj_pts[:, 1] >= 0.0) \n",
    "            and all(reproj_pts[:, 1] < image_height)):\n",
    "            \n",
    "            visible_modules.append((track_id, reproj_pts))\n",
    "    return visible_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79fc05bd-4814-48a4-b2fd-d48435f162ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_list_of_dicts(dicts):\n",
    "    merged = {}\n",
    "    for d in dicts:\n",
    "        merged.update(d)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e393c7b8-28a2-4752-9f8d-9fac723527c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a572cb08ea451a8fdfa97db26b6c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2368.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd961a162ac49fb9421f8b79db6ad6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# merge duplicate modules by projecting each module into each keyframe and finding overlapping modules\n",
    "image_width = 640\n",
    "image_height = 512\n",
    "merge_threshold = 20  # px\n",
    "\n",
    "dists = []\n",
    "\n",
    "merge_candidates = nx.Graph()\n",
    "for frame_name in tqdm.tqdm_notebook(pose_graph.nodes):\n",
    "    \n",
    "    visible_modules = get_visible_modules(\n",
    "        pose_graph, frame_name, module_corners, image_width, image_height)\n",
    "            \n",
    "    # find overlapping modules in the image\n",
    "    all_combinations = list(combinations(range(len(visible_modules)), 2))\n",
    "    for i, j in all_combinations:    \n",
    "        mean_dist = np.mean(np.linalg.norm(visible_modules[i][1] - visible_modules[j][1], axis=1))\n",
    "        dists.append(mean_dist)\n",
    "        if mean_dist < merge_threshold:\n",
    "            merge_candidates.add_node(visible_modules[i][0])\n",
    "            merge_candidates.add_node(visible_modules[j][0])\n",
    "            merge_candidates.add_edge(visible_modules[i][0], visible_modules[j][0])\n",
    "\n",
    "merge_candidates = [list(track_ids) for track_ids in nx.connected_components(merge_candidates)]\n",
    "\n",
    "# fuse observations of merge candidates into a single track and store with first track ID\n",
    "observations_merge_candidates = {}\n",
    "for track_ids in merge_candidates:\n",
    "    obs = [observations[track_id] for track_id in track_ids]\n",
    "    obs = merge_list_of_dicts(obs)\n",
    "    observations_merge_candidates[track_ids[0]] = obs\n",
    "    \n",
    "# re-triangulate\n",
    "module_corners_updated = triangulate_observations(pose_graph, observations_merge_candidates)\n",
    "for track_id, pts_3d in module_corners_updated.items():\n",
    "    module_corners[track_id] = pts_3d\n",
    "    \n",
    "# since we stored the updated module corners under first track ID, we can delete all other track IDs\n",
    "for track_ids in merge_candidates:\n",
    "    for track_id in track_ids[1:]:\n",
    "        del module_corners[track_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf4ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modules(module_corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0bbb6",
   "metadata": {},
   "source": [
    "### Smoothen module corners with graph optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fb5424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45971d5c130451f84cf099aac000db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2368.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corner_merge_threshold = 20  # px\n",
    "\n",
    "merged_corners = []\n",
    "\n",
    "# build graph that encodes connections between module corners\n",
    "for frame_name in tqdm.tqdm_notebook(pose_graph.nodes):\n",
    "    \n",
    "    # get reprojected points of all visible modules\n",
    "    visible_modules = get_visible_modules(\n",
    "        pose_graph, frame_name, module_corners, image_width, image_height)\n",
    "    \n",
    "    track_ids = []\n",
    "    pts = []\n",
    "    for track_id, reproj_pts in visible_modules:\n",
    "        track_ids.extend([track_id for _ in range(5)])  # 4 corners + 1 center\n",
    "        pts.append(reproj_pts)\n",
    "        #plt.scatter(reproj_pts[:, 0], reproj_pts[:, 1])\n",
    "    #plt.show()\n",
    "    \n",
    "    if len(pts) > 0:\n",
    "        pts = np.vstack(pts)\n",
    "\n",
    "        # determine which points are close to another\n",
    "        dist = squareform(pdist(pts))\n",
    "        dist = np.triu(dist)\n",
    "        dist[dist == 0] = np.inf\n",
    "        idxs = np.where(dist < corner_merge_threshold)\n",
    "\n",
    "        for i, j in zip(idxs[0], idxs[1]):\n",
    "            merged_corners.append((track_ids[i], track_ids[j], i%5, j%5))\n",
    "            \n",
    "            \n",
    "# built lookup table (track_id, pts_idx) -> unique vertex_id (int) and reverse\n",
    "track_to_vertex_id = {}\n",
    "vertex_id_to_track = {}\n",
    "for i, (track_id1, track_id2, pts_idx1, pts_idx2) in enumerate(merged_corners):\n",
    "    if (track_id1, pts_idx1) not in track_to_vertex_id.keys():\n",
    "        track_to_vertex_id[(track_id1, pts_idx1)] = 2*i   \n",
    "        vertex_id_to_track[2*i] = (track_id1, pts_idx1)\n",
    "        \n",
    "    if (track_id2, pts_idx2) not in track_to_vertex_id.keys():\n",
    "        track_to_vertex_id[(track_id2, pts_idx2)] = 2*i + 1    \n",
    "        vertex_id_to_track[2*i+1] = (track_id2, pts_idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "915620f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0d597dcfc4437d85625e64fbd40d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=202124.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of vertices: 24727\n",
      "Number of edges: 202124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup optimizer and camera parameters\n",
    "optimizer = g2o.SparseOptimizer()\n",
    "solver = g2o.BlockSolverSE3(g2o.LinearSolverCholmodSE3())\n",
    "solver = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "optimizer.set_algorithm(solver)\n",
    "\n",
    "# add 3D corner points and edges\n",
    "vertex_ids_added = []\n",
    "for track_id1, track_id2, pts_idx1, pts_idx2 in tqdm.tqdm_notebook(merged_corners):\n",
    "    \n",
    "    vertex_id1 = track_to_vertex_id[(track_id1, pts_idx1)]\n",
    "    if vertex_id1 not in vertex_ids_added:\n",
    "        v1 = g2o.VertexPointXYZ()        \n",
    "        v1.set_id(vertex_id1)\n",
    "        pts_3d1 = module_corners[track_id1][pts_idx1]\n",
    "        v1.set_estimate(pts_3d1)\n",
    "        v1.set_fixed(False)\n",
    "        optimizer.add_vertex(v1)\n",
    "        vertex_ids_added.append(vertex_id1)\n",
    "    \n",
    "    vertex_id2 = track_to_vertex_id[(track_id2, pts_idx2)]\n",
    "    if vertex_id2 not in vertex_ids_added:\n",
    "        v2 = g2o.VertexPointXYZ()\n",
    "        v2.set_id(vertex_id2)\n",
    "        pts_3d2 = module_corners[track_id2][pts_idx2]\n",
    "        v2.set_estimate(pts_3d2)\n",
    "        v2.set_fixed(False)\n",
    "        optimizer.add_vertex(v2)\n",
    "        vertex_ids_added.append(vertex_id2)\n",
    "    \n",
    "    # add edge\n",
    "    edge = g2o.EdgePointXYZ()\n",
    "    edge.set_vertex(0, optimizer.vertex(vertex_id1))\n",
    "    edge.set_vertex(1, optimizer.vertex(vertex_id2))\n",
    "    edge.set_measurement(np.array([0, 0, 0]))\n",
    "    edge.set_information(np.identity(3)) # TODO: give lower confidence to camera z coordinate, not easy as world z != camer z\n",
    "    edge.set_robust_kernel(g2o.RobustKernelHuber(np.sqrt(5.99)))\n",
    "    optimizer.add_edge(edge)\n",
    "    \n",
    "print(\"Number of vertices: {}\".format(len(optimizer.vertices())))\n",
    "print(\"Number of edges: {}\".format(len(optimizer.edges())))\n",
    "\n",
    "optimizer.initialize_optimization()\n",
    "optimizer.set_verbose(True)\n",
    "optimizer.optimize(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bb71bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write back result\n",
    "module_corners_estimated = copy.deepcopy(module_corners)\n",
    "for vertex_id, vertex in optimizer.vertices().items():\n",
    "    pts_estimated = vertex.estimate()\n",
    "    track_id, pts_idx = vertex_id_to_track[vertex_id]\n",
    "    module_corners_estimated[track_id][pts_idx] = pts_estimated\n",
    "    #print(vertex_id, pts_estimated, module_corners[track_id][pts_idx], \n",
    "    #      np.linalg.norm(pts_estimated - module_corners[track_id][pts_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c32ae57c-fe56-4aa5-93fd-d670169b5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move module center points into the center of the four corners\n",
    "for track_id in module_corners_estimated.keys():\n",
    "    module_corners_estimated[track_id][0, :] = np.mean(module_corners_estimated[track_id][1:, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c2b168b-5aea-47e9-aa52-49d6a8aa181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_modules(module_corners_estimated)\n",
    "save_modules_geocoords(module_corners_estimated, overall_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc87d6b",
   "metadata": {},
   "source": [
    "### Camera positions to WGS-84 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b072d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps origin is the same for all partial reconstructions\n",
    "gps_positions = []\n",
    "for frame_name in pose_graph.nodes:\n",
    "    pose = pose_graph.nodes[frame_name][\"pose\"]\n",
    "    t = pose[3:]\n",
    "    gps_positions.append(np.array(enu2geodetic(*t, *overall_origin)))\n",
    "gps_positions = np.array(gps_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a0c6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import simplekml\n",
    "gps_positions_new = np.copy(gps_positions)\n",
    "gps_positions_new[:, 0] = gps_positions[:, 1]\n",
    "gps_positions_new[:, 1] = gps_positions[:, 0]\n",
    "gps_positions_new[:, 2] = gps_positions[:, 2]\n",
    "\n",
    "kml_file = simplekml.Kml()\n",
    "kml_file.newlinestring(name=\"trajectory\", coords=gps_positions_new)\n",
    "kml_file.save(os.path.join(mapping_root, \"gps.kml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fca879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
